{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenize Words</th>\n",
       "      <th>Tokenize Words Alphanumeric Only</th>\n",
       "      <th>Sentence Word Count</th>\n",
       "      <th>Row</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Sentiment Scores</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What do you expect? They're savages. One lot s...</td>\n",
       "      <td>['What', 'do', 'you', 'expect', '?', 'They', \"...</td>\n",
       "      <td>['What', 'do', 'you', 'expect', 'They', 'savag...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>Sentiment(polarity=-0.125, subjectivity=0.375)</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I've never seen wildlings do a thing like this...</td>\n",
       "      <td>['I', \"'ve\", 'never', 'seen', 'wildlings', 'do...</td>\n",
       "      <td>['I', 'never', 'seen', 'wildlings', 'do', 'a',...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>['How', 'close', 'did', 'you', 'get', '?']</td>\n",
       "      <td>['How', 'close', 'did', 'you', 'get']</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "      <td>['Close', 'as', 'any', 'man', 'would', '.']</td>\n",
       "      <td>['Close', 'as', 'any', 'man', 'would']</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "      <td>['We', 'should', 'head', 'back', 'to', 'the', ...</td>\n",
       "      <td>['We', 'should', 'head', 'back', 'to', 'the', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>Sentiment(polarity=0.0, subjectivity=0.0)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  What do you expect? They're savages. One lot s...   \n",
       "1  I've never seen wildlings do a thing like this...   \n",
       "2                             How close did you get?   \n",
       "3                            Close as any man would.   \n",
       "4                   We should head back to the wall.   \n",
       "\n",
       "                                      Tokenize Words  \\\n",
       "0  ['What', 'do', 'you', 'expect', '?', 'They', \"...   \n",
       "1  ['I', \"'ve\", 'never', 'seen', 'wildlings', 'do...   \n",
       "2         ['How', 'close', 'did', 'you', 'get', '?']   \n",
       "3        ['Close', 'as', 'any', 'man', 'would', '.']   \n",
       "4  ['We', 'should', 'head', 'back', 'to', 'the', ...   \n",
       "\n",
       "                    Tokenize Words Alphanumeric Only  Sentence Word Count  \\\n",
       "0  ['What', 'do', 'you', 'expect', 'They', 'savag...                   25   \n",
       "1  ['I', 'never', 'seen', 'wildlings', 'do', 'a',...                   21   \n",
       "2              ['How', 'close', 'did', 'you', 'get']                    5   \n",
       "3             ['Close', 'as', 'any', 'man', 'would']                    5   \n",
       "4  ['We', 'should', 'head', 'back', 'to', 'the', ...                    7   \n",
       "\n",
       "   Row Family Name                                Sentiment Scores  Polarity  \\\n",
       "0    0       other  Sentiment(polarity=-0.125, subjectivity=0.375)    -0.125   \n",
       "1    1       other       Sentiment(polarity=0.0, subjectivity=0.0)     0.000   \n",
       "2    2       other       Sentiment(polarity=0.0, subjectivity=0.0)     0.000   \n",
       "3    3       other       Sentiment(polarity=0.0, subjectivity=0.0)     0.000   \n",
       "4    4       other       Sentiment(polarity=0.0, subjectivity=0.0)     0.000   \n",
       "\n",
       "   Subjectivity  \n",
       "0         0.375  \n",
       "1         0.000  \n",
       "2         0.000  \n",
       "3         0.000  \n",
       "4         0.000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script = pd.read_csv('Game_of_Thrones_Script_count_senti.csv')\n",
    "script.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = script.groupby(['Name', 'Family Name'])[['Sentence Word Count']].sum().reset_index().sort_values(by=['Sentence Word Count']\n",
    "                                                                                         , ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_top5 = script[script[\"Name\"].isin(top_20[\"Name\"][:5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_top_20 = script[script[\"Name\"].isin(top_20[\"Name\"][:20])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_top_20 = script_top_20[[\"Sentence\", \"Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_top_20.columns = [\"Sentence\", \"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Go on. Father's watching.</td>\n",
       "      <td>jon snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>And your mother.</td>\n",
       "      <td>jon snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thank you.</td>\n",
       "      <td>sansa stark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Don't think too much, Bran.</td>\n",
       "      <td>jon snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Relax your bow arm.</td>\n",
       "      <td>robb stark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Sentence        Label\n",
       "15    Go on. Father's watching.     jon snow\n",
       "16             And your mother.     jon snow\n",
       "18                   Thank you.  sansa stark\n",
       "21  Don't think too much, Bran.     jon snow\n",
       "22          Relax your bow arm.   robb stark"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_top_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_top_20.to_csv('Game_of_Thrones_Script_top20.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['jon snow', 'jaime lannister', 'cersei lannister',\n",
       "       'tyrion lannister', 'daenerys targaryen'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_top5[\"Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = script_top5['Sentence'] # the features we want to analyze\n",
    "ylabels = script_top5['Name'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxisses/TechnologyStuff/nlp/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cleaner', <__main__.predictors object at 0x7f14a53296a0>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 t...\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function spacy_tokenizer at 0x7f14ac43fd08>,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.38857466063348417\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cersei lannister', 'daenerys targaryen', 'jaime lannister',\n",
       "       'jon snow', 'tyrion lannister'], dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05815035, 0.24910986, 0.03068634, 0.34340225, 0.3186512 ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"Yes, and the dwarf loves his whine and the women\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67871721, 0.04113006, 0.15739864, 0.07543604, 0.04731806]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"The high sparrow annoys me.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15503389, 0.53765287, 0.05786516, 0.08193406, 0.16751403]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"I own the dragons.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06396884, 0.24445445, 0.43925265, 0.18432098, 0.06800308]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"I can't fight anymore because I lost my hand.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23081516, 0.02145236, 0.12624394, 0.31208422, 0.30940431]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"My father is Eddard Stark.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4024775 , 0.03383039, 0.1140324 , 0.13279097, 0.31686874]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"My father is Tywin Lannister.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23885739, 0.2838366 , 0.11847671, 0.20951673, 0.14931258]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"The north remembers.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model was generic. In the next step I will try to tune the model a little and use Season 1 - 7 for train and cross validation. Then let's see how well this model performs on Season 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = script_top5[script_top5[\"Season\"] != \"Season 8\"]['Sentence'] # the features we want to analyze\n",
    "ylabels = script_top5[script_top5[\"Season\"] != \"Season 8\"]['Name'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_holdout = script_top5[script_top5[\"Season\"] == \"Season 8\"]['Sentence']#\n",
    "ylabels_holdout = script_top5[script_top5[\"Season\"] == \"Season 8\"]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cleaner',\n",
       "                                        <__main__.predictors object at 0x7f14a53296d8>),\n",
       "                                       ('vectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        preproces...\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'classifier__solver': ['newton-cg', 'liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "hyperparams = {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], \"classifier__solver\": [\"newton-cg\", \"liblinear\"]}\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe2 = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe2, param_grid = hyperparams, cv=10)\n",
    "\n",
    "# model generation\n",
    "grid.fit(X,ylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.1, 'classifier__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35566109070157287"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.3434343434343434\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Predicting with my holdout dataset (Season 8)\n",
    "predictions = best_model.predict(X_holdout)\n",
    "print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(ylabels_holdout, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cersei lannister', 'daenerys targaryen', 'jaime lannister',\n",
       "       'jon snow', 'tyrion lannister'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11291686, 0.13675034, 0.09031177, 0.1563509 , 0.50367012]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba([\"Yes, and the dwarf loves his whine and the women\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26870395, 0.17181349, 0.16113636, 0.1465391 , 0.2518071 ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba([\"The love for my children is above everything\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09152649, 0.30541641, 0.13231777, 0.23478667, 0.23595265]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba([\"I will break the chains and free millions of people.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10488837, 0.18229382, 0.19773547, 0.30237345, 0.2127089 ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba([\"I won't be able to fight ever again...\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21094134, 0.08340677, 0.14699467, 0.14782952, 0.4108277 ]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict_proba([\"My father is Tywin Lannister\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
